{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 北大第五课：深度学习处理器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 智能应用成为计算机主要负载\n",
    "\n",
    "寒武纪做**智能芯片**最主要的`目标`就是去**完成各种各样的智能计算任务**，为它们提供核心芯片的支撑。\n",
    "\n",
    "### 智能应用\n",
    "* `超级计算机`上做的**商业分析**、**药物研制**等。\n",
    "* `数据中心`的**广告推荐**、**自动翻译**等。\n",
    "* `手机`里的**语音识别**、**图像分析**等。\n",
    "* `嵌入式设备`方面的**机器人**、**自动驾驶**、**手环**、**手表**等。\n",
    "\n",
    "### 智能任务处理方法\n",
    "* 符号主义\n",
    "* 行为主义\n",
    "* 联结主义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深度学习\n",
    "\n",
    "### 深度学习到底是怎么工作的\n",
    "> 第一层可以看到一些局部简单的特征，比如对角线这样的东西；再下一层神经网络做了一个更大范围的卷积，会看到一个更大范围、更复杂的特征，比如说由环、圈、点这样类似的东西；到下一层我们可以看到更大范围更复杂的。进行逐级抽象之后，就可以对一个复杂的图片进行理解。\n",
    "\n",
    "> `从鲁棒性条件来说，深度学习和人还是有一点点的差距的，但是这个差距我觉得是技术上弥补的，可能需要五年或者更长时间。`\n",
    "\n",
    "### 深度学习加增强学习的框架\n",
    "\n",
    "> 2014年DeepMind就已经提出了一套深度学习加增强学习的框架，这里面的含义就是说深度学习就是一个人工神经网络，但是这些人工神经网络的拓扑、参数、权重是怎么得到的呢？它是通过增强学习这套框架不断在现实中学习、调节、不断在自然界中去使用神经网络，然后计算机再返回去调整这个神经网络的权重。\n",
    "\n",
    "> 当时DeepMind用它去教会了计算机打很多种小游戏，大概有几十种。比如贪吃蛇这种游戏，用这套框架，DeepMind就告诉计算机，只需要看着屏幕，只需要把这个游戏的分数打得尽量高，不需要告诉计算机游戏规则是什么。\n",
    "\n",
    "> DeepMind让计算机学会了打40多种小游戏，而且有20多种超过了人类的世界记录。然后，DeepMind又把这套深度学习加增强学习的框架用到了下围棋方面。\n",
    "\n",
    "### [APM （每分钟操作次数）](https://baike.baidu.com/item/APM/516) \n",
    "* 提高APM的方法：在电脑上打开100个窗口，使用鼠标控制以最快的速度关闭它。\n",
    "* `如果有一天机器在使用APM小于等于人的情况下，玩游戏战胜了人，这样才能说机器在智能上彻底战胜了人。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 芯片与神经网络\n",
    "\n",
    "### 为什么需要神经网络处理器\n",
    "* 神经网络是处理智能计算迄今最好的方法\n",
    "* 通用CPU/GPU处理神经网络效率低下\n",
    "    * 谷歌大脑：2012年用1.6万个CPU核跑7天完成猫脸识别训练。\n",
    "    * AlphaGo：它在跟李世石下棋的时候，当时用了1000多个CPU和200个GPU，平均每盘电费就需要接近3000美元。这反映了一个很实际的问题：现在人工智能算法的能耗实在是太高了，不管CPU还是GPU，都不足够把这些算法真正地用起来。\n",
    "    * 目前有好多算法非常不错，但并没有落地。\n",
    "    * 如何从1000亿突触增长到100万亿突解（人脑规模）？`突解：神经元之间的连接`\n",
    "\n",
    "### 专门的神经网络处理器\n",
    "* 图形处理器 GPU\n",
    "* 信号处理 DSP\n",
    "* 未来每台计算机可能都需要一个专门的深度学习处理器\n",
    "    * 从云服务器到智能手机\n",
    "    * 一个和GPU同样规模的潜在市场：每年6.4亿芯片，数百亿美元销售额\n",
    "    * 寒武纪是此领域的先行者\n",
    "* 深度学习处理器：DianNao\n",
    "    * 寒武纪2012开创深度学习处理器\n",
    "    * 通用CPU十分之一的面积上做到了它百倍的性能\n",
    "* 寒武纪目前将深度学习处理器扩展为机器学习处理器。\n",
    "* 芯片的研制周期很长。芯片的成本非常高，做一个7nm芯片，流片成本就应该在1亿到2亿之间人民币，卖出百万片才可能回本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 寒武纪的学术贡献\n",
    "\n",
    "### 虚拟化的同时降低开销\n",
    "> 有限规模的硬件怎么应对任意规模的算法？我们的思想很简单：硬件神经元的虚拟化，我通过复用，把有限规模的硬件虚拟成大规模的人工神经网络。\n",
    "\n",
    "> 把这个大的要处理的逻辑人工神经网络切成很多个小块，每个小块我们映射到硬件上的每个小块上去处理，通过蚂蚁搬大米的方式：用一个有限大小的硬件，处理另一大规模的算法。有一个很大的好处是：如果算法变了，硬件并不需要变，比如再加一层，或者说再加一些神经元，只要把虚拟化的软件稍微调一下就可以。\n",
    "\n",
    "> 但是，在这个虚拟化的过程中，其实是带来了开销，也就是需要做一些数据搬运，要把算法神经元或逻辑神经元搬到硬件神经元上来。所以这里面我们有很多更细节的技术，比如搬运的过程中，怎么保证能够不断地重用神经元或者突触的数据。这样就导致一个结果：一方面在虚拟化中让有限规模的硬件处理任意规模的算法；另外一个方面，虚拟化过程中，数据基本上是能够大幅度重用的，没有太多数据搬运的开销。\n",
    "\n",
    "### 指令集\n",
    "> 结构固定的硬件如何去应对千变万化的算法。这里面的思想是：自动化抽取各种各样的深度学习+机器学习算法的贡献的基本算子。\n",
    "* 为什么做深度学习指令集要用机器学习呢？\n",
    "> 万变不离其宗，基本的trick都是几十年来传承下来，就那么几招，而这些招数就在上百种的机器学习算法里。把这上百种机器学习算法都分析一遍，我们就能确保，即便未来再出了新的深度学习算法，也跳不出我们的手掌心。\n",
    "* 分析套路具体是做什么呢？\n",
    "    * 第一、把这些算法全部拉出来，做一个最耗时最需要运算操作的集合，做这个合集是为了分析做深度学习处理器需要什么样的部件。\n",
    "    * 第二、寻找机器学习算法中的缓存的，读取数据的共性，自己来设计变量存储。所以就看到很多机器学习算法：KNN、K-means、SVM、朴素贝叶斯、贝叶斯网络等等。\n",
    "* 总结\n",
    "    * 主要运算：向量内积，向量距离，计数，非线性函数，排序\n",
    "    * 数据局部性特征：“三个柱子”，一个数据局部现象的共性，用机器学习的方法，对机器学习的算法再做一次分析，把一个机器学习算法里面所有的变量都拿出来，对它做一个聚类。然后发现，不管重用模式，重用距离还是重用次数，从访问宽度上来看，一般来说每个机器学习算法里面的变量也就两到三类。\n",
    "    * 出现一个新的算法，只需要指令之间的拼接组合，就能够把新的算法给完成出来，这就解决了固定的硬件怎么去应对千变万化算法的这个问题。\n",
    "\n",
    "### 稀疏的方法\n",
    "`做硬件的这些人，包括我们，会受到最大的能耗限制：在手机上不能超过1W，在服务器上因为封装散热的限制，芯片也不能超过300W。`\n",
    "* 如何应对呢？我们提出了一套稀疏神经网络处理器的这样的一个思想。因为神经网络对计算误差具有一定的容忍能力，尤其是对它进行一些重训练之后还要做一些代偿，于是就需要对神经网络进行稀疏化，这样就能在有限的能耗下完成高精度的智能处理。\n",
    "* 但是这里有一个问题：稀疏化的过程中，如何保证精度？稀疏掉了90%的神经元，在有的场景下可能精度不会降低，有的场景下可能精度就降低了。我们`提出了一整套软硬件的执行方法，可以自动判断精度有没有下降`。\n",
    "* 到底多小是非常小到可以稀疏化掉呢？就是阈值。比如这里设0.01，如果发现0.01为阈值，最后精度下降了，那就把阈值调低一点，反过来说当用户体验不受影响的时候又可以把阈值调高一点。思路就是在运行时的环境中做动态调节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 寒武纪的梦想\n",
    "\n",
    "> 希望把代表性智能算法的处理速度跟性能功耗比提升10000倍。为什么是10000倍呢？因为谷歌大脑是1.6万个CPU核，如果能够提升1万倍就意味着能够把谷歌大脑这样的东西能够放到一个手机里。\n",
    "\n",
    "> 这样的手机，不仅仅是帮助我们本地实时地完成各种图像语音和文本的识别和理解，更重要是它还具备训练能力，能耗还很低，那么它就可以不间断的去观察人、社会和自然界的行为，不断提升自己的智能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI芯片组产品\n",
    "* 中央处理器（CPU）\n",
    "* 图形处理器（GPU）\n",
    "* 神经网络处理器（NNP）\n",
    "* 专用集成电路（ASIC）\n",
    "* 现场可编程门阵列（FPGA）\n",
    "* 精简指令集（RISC）处理器\n",
    "* 加速器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考资料\n",
    "\n",
    "* [中科院计算所研究员陈云霁：深度学习处理器的现状及发展 | 北大AI公开课笔记](http://www.sohu.com/a/226770566_610300)\n",
    "* [全球AI芯片企业排行：英伟达第1，华为第12（七家中国公司入围Top24）](http://t.cj.sina.com.cn/articles/view/6105753431/16bee6757027006fi1?from=tech)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
